{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import getopt\n",
    "import os, sys\n",
    " \n",
    "# Main path to your caffe installation\n",
    "caffe_root = '/home/payam/workspace/caffe/'\n",
    "\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "import caffe\n",
    " \n",
    "# Model prototxt file\n",
    "#model_prototxt = caffe_root + 'models/bvlc_reference_caffenet/deploy.prototxt'\n",
    "model_prototxt = caffe_root + 'models/bvlc_googlenet/deploy.prototxt'\n",
    " \n",
    "# Model caffemodel file\n",
    "#model_trained = caffe_root + 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'\n",
    "model_trained = caffe_root + 'models/bvlc_googlenet/bvlc_googlenet.caffemodel'\n",
    " \n",
    "# File containing the class labels\n",
    "imagenet_labels = caffe_root + 'data/ilsvrc12/synset_words.txt'\n",
    " \n",
    "# Path to the mean image (used for input processing)\n",
    "mean_path = caffe_root + 'python/caffe/imagenet/ilsvrc_2012_mean.npy'\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "# Name of the layer we want to extract\n",
    "#layer_name = 'fc8'\n",
    "layer_name = 'pool5/7x7_s1'\n",
    "layer_name2 = 'loss3/classifier'\n",
    "layer_name3 = 'pool5/drop_7x7_s1'\n",
    "def folder_feature_extractor(input_folder):\n",
    "    caffe.set_mode_cpu()\n",
    "    net = caffe.Classifier(model_prototxt, model_trained,\n",
    "                           mean=np.load(mean_path).mean(1).mean(1),\n",
    "                           channel_swap=(2,1,0),\n",
    "                           raw_scale=255,\n",
    "                           image_dims=(256, 256))\n",
    " \n",
    "    with open(imagenet_labels) as f:\n",
    "        labels = f.readlines()\n",
    "    feature_list = []\n",
    "    feature_list2 = []\n",
    "    feature_list3 = []\n",
    "    for i in range(1,101):\n",
    "        net = caffe.Classifier(model_prototxt, model_trained,\n",
    "                           mean=np.load(mean_path).mean(1).mean(1),\n",
    "                           channel_swap=(2,1,0),\n",
    "                           raw_scale=255,\n",
    "                           image_dims=(256, 256))\n",
    "        file_name =  str(i).zfill(3) + '.jpg'\n",
    "        file_name = input_folder + file_name\n",
    "        #print file_name\n",
    "        image = caffe.io.load_image(file_name)\n",
    "        #plt.imshow(image)\n",
    "        #plt.figure(i+1)\n",
    "        prediction = net.predict([image], oversample=False)\n",
    "        features = net.blobs[layer_name].data[0].reshape(1,-1)\n",
    "        features2 = net.blobs[layer_name2].data[0].reshape(1,-1)\n",
    "        #features3 = net.blobs[layer_name3].data[0].reshape(1,-1)\n",
    "        #print sum(features[0])\n",
    "        #print labels[prediction[0].argmax()].strip() , ' (', prediction[0][prediction[0].argmax()] , ')'\n",
    "        #for i in features[0]:\n",
    "        #    print i\n",
    "        #print type(features)\n",
    "        #print len(features)\n",
    "        feature_list.append(features[0])\n",
    "        feature_list2.append(features2[0])\n",
    "        #feature_list3.append(features3[0])\n",
    "        #print '-------------------------------------'\n",
    "    return [feature_list, feature_list2]\n",
    "\n",
    "ref1 = folder_feature_extractor('/home/payam/dataset/cd_covers/Reference/')[0]\n",
    "ref2 = folder_feature_extractor('/home/payam/dataset/cd_covers/Reference/')[1]\n",
    "print ref1[0].shape\n",
    "print ref2[0].shape\n",
    "test1 = folder_feature_extractor('/home/payam/dataset/cd_covers/Droid/')[0]\n",
    "test2 = folder_feature_extractor('/home/payam/dataset/cd_covers/Droid/')[1]\n",
    "print test1[0].shape\n",
    "print test2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ref = np.loadtxt('/home/payam/dataset/cd_covers/Reference/caffenet_features.txt')\n",
    "test = np.loadtxt('/home/payam/dataset/cd_covers/Droid/caffenet_features.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "count_dist = 0\n",
    "count_corr = 0\n",
    "count_coef = 0\n",
    "count_pear = 0\n",
    "count_comb = 0\n",
    "print 'ind   dist   corr   pear   comb'\n",
    "for j in range(0,100):\n",
    "    min_dist = 9999999999.0\n",
    "    min_index = -1\n",
    "    max_coef = 0.0\n",
    "    max_coef_index = -1\n",
    "    max_corr = 0.0\n",
    "    max_corr_index = -1\n",
    "    max_pear = 0.0\n",
    "    max_pear_index = -1\n",
    "    for i in range(0,100):\n",
    "        coef = np.mean(np.corrcoef(ref[i], test[j]))\n",
    "        corr = np.correlate(ref[i], test[j])\n",
    "        dist = np.linalg.norm(ref[i] - test[j])\n",
    "        pear = abs(pearsonr(ref[i], test[j])[0])\n",
    "        if dist < min_dist:\n",
    "            min_index = i\n",
    "            min_dist = dist\n",
    "        if corr > max_corr:\n",
    "            max_corr_index = i\n",
    "            max_corr = corr\n",
    "        if pear > max_pear:\n",
    "            max_pear_index = i\n",
    "            max_pear = pear\n",
    "    #print '%3d %6d %6d %6d '%(j, min_index, max_corr_index, max_pear_index)\n",
    "    flag = False\n",
    "    #count = 0\n",
    "    comb = np.zeros((100))\n",
    "    comb[min_index] += 39\n",
    "    comb[max_corr_index] += 21\n",
    "    comb[max_pear_index] += 44\n",
    "    comb_index = np.argmax(comb)\n",
    "    if comb_index == j:\n",
    "        count_comb += 1\n",
    "        flag = True\n",
    "    if j == min_index:\n",
    "        count_dist += 1\n",
    "        flag = True\n",
    "    if j == max_corr_index:\n",
    "        count_corr += 1\n",
    "        flag = True\n",
    "    if j == max_pear_index:\n",
    "        count_pear += 1\n",
    "        flag = True\n",
    "    if flag:\n",
    "        pass\n",
    "        #print '%3d %6d %6d %6d %6d'%(j, min_index, max_corr_index, max_pear_index, comb_index)\n",
    "    \n",
    "print 'distance:    ', count_dist\n",
    "print 'correlation: ', count_corr\n",
    "#print 'coef:        ', count_coef\n",
    "print 'pearson    : ', count_pear\n",
    "print 'combination: ', count_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
